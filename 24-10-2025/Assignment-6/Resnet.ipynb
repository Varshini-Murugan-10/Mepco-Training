{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWWaMzTPNe0_",
        "outputId": "ab4d1a6b-4502-4047-f5fb-09a281fe604a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training ResNet50...\n",
            "Epoch 1/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 102ms/step - accuracy: 0.1055 - loss: 2.3631 - val_accuracy: 0.1004 - val_loss: 2.2951\n",
            "Epoch 2/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 98ms/step - accuracy: 0.1243 - loss: 2.2935 - val_accuracy: 0.1653 - val_loss: 2.2821\n",
            "Epoch 3/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 98ms/step - accuracy: 0.1446 - loss: 2.2776 - val_accuracy: 0.1895 - val_loss: 2.2609\n",
            "Fine-tuning ResNet50...\n",
            "Epoch 1/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 140ms/step - accuracy: 0.3179 - loss: 1.8752 - val_accuracy: 0.4812 - val_loss: 1.4853\n",
            "Epoch 2/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 132ms/step - accuracy: 0.4897 - loss: 1.4367 - val_accuracy: 0.4498 - val_loss: 1.5827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a4622ce88c0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# -------------------------------------\n",
        "# 1. Setup (Colab has TF pre-installed)\n",
        "# -------------------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# -------------------------------------\n",
        "# 2. Load a sample dataset (replace with your own)\n",
        "# Colab provides tf.keras.datasets, here we use CIFAR-10 for demo\n",
        "# -------------------------------------\n",
        "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize images\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_val = x_val.astype(\"float32\") / 255.0\n",
        "\n",
        "# Resize images to 224x224 (needed for ResNet/MobileNet)\n",
        "resize_layer = tf.keras.Sequential([\n",
        "    layers.Resizing(224, 224)\n",
        "])\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).map(lambda x, y: (resize_layer(x), y))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32).map(lambda x, y: (resize_layer(x), y))\n",
        "\n",
        "# -------------------------------------\n",
        "# 3. Transfer Learning with ResNet50\n",
        "# -------------------------------------\n",
        "base_resnet = tf.keras.applications.ResNet50(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "base_resnet.trainable = False  # freeze backbone\n",
        "\n",
        "resnet_model = models.Sequential([\n",
        "    base_resnet,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation=\"softmax\")  # CIFAR-10 has 10 classes\n",
        "])\n",
        "\n",
        "resnet_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Training ResNet50...\")\n",
        "resnet_model.fit(train_ds, validation_data=val_ds, epochs=3)\n",
        "\n",
        "\n",
        "# -------------------------------------\n",
        "# 4. Fine-tuning (optional: unfreeze last few layers)\n",
        "# -------------------------------------\n",
        "base_resnet.trainable = True\n",
        "for layer in base_resnet.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "resnet_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # lower LR\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Fine-tuning ResNet50...\")\n",
        "resnet_model.fit(train_ds, validation_data=val_ds, epochs=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.save(\"resnet.keras\")"
      ],
      "metadata": {
        "id": "fvVp40mPRjQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/cat.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEDvnyUAQi3i",
        "outputId": "f06a4ab3-b878-47af-f2bf-3e2babd50e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "Predicted class: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/deer.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea0763d-5de8-47d1-a89f-a16de5bf7891",
        "id": "meeXnQoTRJH2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Predicted class: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/auto.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19008fb-796f-47a5-cebf-646bd4d83e8b",
        "id": "WxugX386RMXE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/aero.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7daf73-e284-44cc-91b6-d3bdbab354e1",
        "id": "AIwE8PWeROzg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/bird.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b14e491-38a0-4576-e0d3-1169f38e6599",
        "id": "6rBCSN1ERRIl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Predicted class: 2\n"
          ]
        }
      ]
    }
  ]
}