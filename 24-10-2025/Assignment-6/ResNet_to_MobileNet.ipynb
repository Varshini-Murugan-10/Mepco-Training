{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWWaMzTPNe0_",
        "outputId": "bb18dd92-0259-469e-ea71-2b6b9bebf7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training Mobilenet...\n",
            "Epoch 1/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 49ms/step - accuracy: 0.5316 - loss: 1.3956 - val_accuracy: 0.7744 - val_loss: 0.6586\n",
            "Epoch 2/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.7466 - loss: 0.7343 - val_accuracy: 0.7938 - val_loss: 0.5945\n",
            "Epoch 3/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 36ms/step - accuracy: 0.7779 - loss: 0.6430 - val_accuracy: 0.8005 - val_loss: 0.5660\n",
            "Fine-tuning MobileNetV2...\n",
            "Epoch 1/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 53ms/step - accuracy: 0.7144 - loss: 0.8379 - val_accuracy: 0.8177 - val_loss: 0.5247\n",
            "Epoch 2/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.8168 - loss: 0.5373 - val_accuracy: 0.8397 - val_loss: 0.4576\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b498c98a720>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# -------------------------------------\n",
        "# 1. Setup (Colab has TF pre-installed)\n",
        "# -------------------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# -------------------------------------\n",
        "# 2. Load a sample dataset (replace with your own)\n",
        "# Colab provides tf.keras.datasets, here we use CIFAR-10 for demo\n",
        "# -------------------------------------\n",
        "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize images\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_val = x_val.astype(\"float32\") / 255.0\n",
        "\n",
        "# Resize images to 224x224 (needed for ResNet/MobileNet)\n",
        "resize_layer = tf.keras.Sequential([\n",
        "    layers.Resizing(224, 224)\n",
        "])\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).map(lambda x, y: (resize_layer(x), y))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32).map(lambda x, y: (resize_layer(x), y))\n",
        "\n",
        "# -------------------------------------\n",
        "# 3. Transfer Learning with ResNet50\n",
        "# -------------------------------------\n",
        "base_mobilenet = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "base_mobilenet.trainable = False  # freeze backbone\n",
        "\n",
        "mobilenet_model = models.Sequential([\n",
        "    base_mobilenet,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation=\"softmax\")  # CIFAR-10 has 10 classes\n",
        "])\n",
        "\n",
        "mobilenet_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Training Mobilenet...\")\n",
        "mobilenet_model.fit(train_ds, validation_data=val_ds, epochs=3)\n",
        "\n",
        "\n",
        "# -------------------------------------\n",
        "# 4. Fine-tuning (optional: unfreeze last few layers)\n",
        "# -------------------------------------\n",
        "base_mobilenet.trainable = True\n",
        "for layer in base_mobilenet.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "mobilenet_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # lower LR\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Fine-tuning MobileNetV2...\")\n",
        "mobilenet_model.fit(train_ds, validation_data=val_ds, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_model.save(\"Mobilenet.keras\")"
      ],
      "metadata": {
        "id": "fvVp40mPRjQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/bird.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = mobilenet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317ab632-4a35-4183-f669-5c264dd1ce5f",
        "id": "6rBCSN1ERRIl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
            "Predicted class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/cat.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = mobilenet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7tpwxL1Vg4U",
        "outputId": "0e8f9873-1ff8-4637-cc9c-699b78ec1e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Predicted class: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/aero.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = mobilenet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b_pyXukVjRG",
        "outputId": "6d7db6cb-e05e-4c19-dcf5-df7cf70a05b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/auto.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = mobilenet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4vpXGb1VmTX",
        "outputId": "8edba726-e060-4013-bf88-0db1c60c5975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Predicted class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/deer.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = mobilenet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "id": "v-F-M5xrVt2n",
        "outputId": "57f19e9c-86e5-44b1-caf2-c882e8510763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Predicted class: 4\n"
          ]
        }
      ]
    }
  ]
}