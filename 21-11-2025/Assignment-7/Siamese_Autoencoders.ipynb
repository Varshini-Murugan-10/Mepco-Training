{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImTqjrJ9YlT8"
      },
      "source": [
        "***1.Build a Siamese network for part matching with limited samples***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wA2RsRm9CYX",
        "outputId": "00e40449-57f0-4440-aa3e-65590d8afc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch 2.8.0+cu126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 94/94 [00:18<00:00,  5.19it/s, loss=0.476]\n",
            "Epoch 2/3: 100%|██████████| 94/94 [00:18<00:00,  5.20it/s, loss=0.373]\n",
            "Epoch 3/3: 100%|██████████| 94/94 [00:17<00:00,  5.40it/s, loss=0.338]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Siamese training finished\n",
            "label 1.0 logit 1.1607321500778198\n",
            "label 1.0 logit 1.2807942628860474\n",
            "label 0.0 logit -6.93443489074707\n",
            "label 0.0 logit -1.1151032447814941\n",
            "label 0.0 logit -13.29568862915039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch torchvision tqdm\n",
        "\n",
        "import torch, random\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "print(\"torch\", torch.__version__)\n",
        "\n",
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, base_dataset, transform=None, num_pairs=6000):\n",
        "        self.base = base_dataset\n",
        "        self.transform = transform\n",
        "        self.num_pairs = num_pairs\n",
        "        self.class_to_idx = {}\n",
        "        for i in range(len(self.base)):\n",
        "            _, label = self.base[i]\n",
        "            self.class_to_idx.setdefault(label, []).append(i)\n",
        "        self.classes = list(self.class_to_idx.keys())\n",
        "    def __len__(self): return self.num_pairs\n",
        "    def __getitem__(self, idx):\n",
        "        if random.random() < 0.5:\n",
        "            cls = random.choice(self.classes)\n",
        "            i1, i2 = random.sample(self.class_to_idx[cls], 2)\n",
        "            img1, _ = self.base[i1]\n",
        "            img2, _ = self.base[i2]\n",
        "            label = 1.0\n",
        "        else:\n",
        "            c1, c2 = random.sample(self.classes, 2)\n",
        "            i1 = random.choice(self.class_to_idx[c1])\n",
        "            i2 = random.choice(self.class_to_idx[c2])\n",
        "            img1, _ = self.base[i1]\n",
        "            img2, _ = self.base[i2]\n",
        "            label = 0.0\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self, embedding_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7,512), nn.ReLU(),\n",
        "            nn.Linear(512,embedding_dim)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embedding_dim,128), nn.ReLU(),\n",
        "            nn.Linear(128,1)\n",
        "        )\n",
        "    def embed(self,x): return self.cnn(x)\n",
        "    def forward(self,x1,x2):\n",
        "        e1 = self.embed(x1)\n",
        "        e2 = self.embed(x2)\n",
        "        dist = torch.abs(e1-e2)\n",
        "        return self.classifier(dist).squeeze(1)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_base = FashionMNIST(root='./data', train=True, download=True, transform=None)\n",
        "ds = SiameseDataset(train_base, transform=transform, num_pairs=6000)\n",
        "dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=2)\n",
        "model = SiameseNet().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "epochs = 3\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    pbar = tqdm(dl, desc=f'Epoch {ep+1}/{epochs}')\n",
        "    running = 0.0\n",
        "    for x1,x2,y in pbar:\n",
        "        x1,x2,y = x1.to(device), x2.to(device), y.to(device)\n",
        "        out = model(x1,x2)\n",
        "        loss = criterion(out,y)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        running += loss.item()\n",
        "        pbar.set_postfix(loss=running/(pbar.n+1))\n",
        "print(\"Siamese training finished\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for _ in range(5):\n",
        "        idx = random.randrange(len(ds))\n",
        "        x1,x2,y = ds[idx]\n",
        "        logits = model(x1.unsqueeze(0).to(device), x2.unsqueeze(0).to(device))\n",
        "        print(\"label\", float(y.item()), \"logit\", float(logits.item()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "kkRByQZcTnka",
        "outputId": "a8f4d5ed-c2fc-43c5-9b64-4984c166e551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity: 0.7711002230644226\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "transform = T.Compose([T.Grayscale(), T.Resize((28,28)), T.ToTensor()])\n",
        "\n",
        "img1 = transform(Image.open(\"/content/download.webp\")).unsqueeze(0).to(device)\n",
        "img2 = transform(Image.open(\"/content/shopping (2).webp\")).unsqueeze(0).to(device)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
        "ax[0].imshow(img1.squeeze().cpu().numpy(), cmap='gray')\n",
        "ax[0].set_title(\"Image 1\")\n",
        "ax[1].imshow(img2.squeeze().cpu().numpy(), cmap='gray')\n",
        "ax[1].set_title(\"Image 2\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logit = model(img1, img2)\n",
        "    prob = torch.sigmoid(logit).item()\n",
        "    print(\"Similarity:\", prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWPqIMfseTRF"
      },
      "source": [
        "***2.Train an Autoencoder on defect free samples to detect anomalies***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XahUQkAggVOm",
        "outputId": "3cb63caa-f3e9-4e01-8518-110b977f94c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'mvtec-ad' dataset.\n",
            "Path to dataset files: /kaggle/input/mvtec-ad\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ipythonx/mvtec-ad\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uThcfxerlw32"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Il-VTxnegi4",
        "outputId": "106b3a92-71c8-4ebd-f740-2f23c7475163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch 2.8.0+cu126\n",
            "Found 6612 images for training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AE Epoch 1/5: 100%|██████████| 207/207 [04:14<00:00,  1.23s/it, loss=0.0218]\n",
            "AE Epoch 2/5: 100%|██████████| 207/207 [03:55<00:00,  1.14s/it, loss=0.00663]\n",
            "AE Epoch 3/5: 100%|██████████| 207/207 [03:49<00:00,  1.11s/it, loss=0.00512]\n",
            "AE Epoch 4/5: 100%|██████████| 207/207 [03:58<00:00,  1.15s/it, loss=0.00464]\n",
            "AE Epoch 5/5: 100%|██████████| 207/207 [03:54<00:00,  1.13s/it, loss=0.00416]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autoencoder training done\n",
            "Sample reconstruction MSE: 0.011660666204988956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os, torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "print(\"torch\", torch.__version__)\n",
        "\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(3,32,4,2,1), nn.ReLU(),\n",
        "            nn.Conv2d(32,64,4,2,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,128,4,2,1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*8*8, latent_dim)\n",
        "        )\n",
        "        self.dec_lin = nn.Linear(latent_dim, 128*8*8)\n",
        "        self.dec = nn.Sequential(\n",
        "            nn.Unflatten(1,(128,8,8)),\n",
        "            nn.ConvTranspose2d(128,64,4,2,1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64,32,4,2,1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32,3,4,2,1), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        z = self.enc(x)\n",
        "        xhat = self.dec(self.dec_lin(z))\n",
        "        return xhat\n",
        "\n",
        "good_dir = '/kaggle/input/mvtec-ad'\n",
        "transform = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
        "\n",
        "ds = None\n",
        "dl = None\n",
        "\n",
        "if os.path.exists(good_dir):\n",
        "    ds = ImageFolder(good_dir, transform=transform)\n",
        "    dl = DataLoader(ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "    print(\"Found\", len(ds), \"images for training\")\n",
        "else:\n",
        "    print(\"Please set good_dir to your folder with training images (ImageFolder structure)\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ConvAutoencoder().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "epochs = 5\n",
        "\n",
        "if dl is not None:\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        pbar = tqdm(dl, desc=f'AE Epoch {ep+1}/{epochs}')\n",
        "        running = 0.0\n",
        "        for x,_ in pbar:\n",
        "            x = x.to(device)\n",
        "            xhat = model(x)\n",
        "            loss = criterion(xhat, x)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            running += loss.item()\n",
        "            pbar.set_postfix(loss=running/(pbar.n+1))\n",
        "    print(\"Autoencoder training done\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        if len(ds) > 0:\n",
        "            x,_ = ds[0]\n",
        "            x = x.unsqueeze(0).to(device)\n",
        "            xhat = model(x)\n",
        "            mse = F.mse_loss(xhat, x).item()\n",
        "            print(\"Sample reconstruction MSE:\", mse)\n",
        "        else:\n",
        "            print(\"Cannot perform sample reconstruction: Dataset is empty.\")\n",
        "else:\n",
        "    print(\"Autoencoder training skipped due to missing or invalid training data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QxLeVThYYNUD"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}